{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(images,labels),(_,_) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape , labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20f2ac07e10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images/127.5 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0, 1.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.min() , images.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.expand_dims(images,-1)  #用tensorflow方法还要对数据进行转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " dataset = tf.data.Dataset.from_tensor_slices((images,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((28, 28, 1), ()), types: (tf.float64, tf.uint8)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "noise_dim = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(60000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    noise = layers.Input(shape=((noise_dim)))\n",
    "    label = layers.Input(shape=(()))\n",
    "    \n",
    "    x = layers.Embedding(10,50,input_length=1)(label)\n",
    "    x = layers.concatenate([seed,x])\n",
    "    x = layers.Dense(3*3*128,use_bias=False)(x)\n",
    "    x = layers.Reshape((3,3,128))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(64,(3,3), strides=(2,2),use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)   #(7,7,,64)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(32,(3,3), strides=(2,2),padding='same',use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)  #(14,14,32)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(1,(3,3), strides=(2,2),padding='same',use_bias=False)(x)\n",
    "    x = layers.Activation('tanh')(x)    #（28，28，1）\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[seed,label], outputs = x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50)           500         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 100)          0           input_1[0][0]                    \n",
      "                                                                 embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1152)         115200      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 3, 3, 128)    0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 3, 3, 128)    512         reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 3, 3, 128)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 7, 7, 64)     73728       re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 7, 7, 64)     256         conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 7, 7, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 14, 14, 32)   18432       re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 14, 14, 32)   128         conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 14, 14, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 28, 28, 1)    288         re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 28, 28, 1)    0           conv2d_transpose_2[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 209,044\n",
      "Trainable params: 208,596\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gen = generator()\n",
    "gen.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    image = layers.Input(shape=(28,28,1))\n",
    "    label = layers.Input(shape=(()))\n",
    "    \n",
    "    x = layers.Embedding(10,28*28,input_length=1)(label) #变成图像大小的向量方便变形成图像大小\n",
    "    x = layers.Reshape((28,28,1))(x)\n",
    "    x = layers.concatenate([x,image])\n",
    "    \n",
    "    x = layers.Conv2D(32,(3,3),strides=(2,2),padding='same',use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    x = layers.Conv2D(64,(3,3),strides=(2,2),padding='same',use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    x = layers.Conv2D(128,(3,3),strides=(2,2),padding='same',use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    out_logits = layers.Dense(1)(x)   #未进行激活\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[image,label], outputs = out_logits)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 784)          7840        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 28, 28, 1)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 28, 28, 2)    0           reshape_1[0][0]                  \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 14, 14, 32)   576         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 14, 14, 32)   128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 14, 14, 32)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 14, 14, 32)   0           leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 7, 7, 64)     18432       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 7, 7, 64)     256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 7, 7, 64)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 64)     0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 4, 4, 128)    73728       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 4, 4, 128)    512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 4, 4, 128)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 4, 4, 128)    0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            2049        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 103,521\n",
      "Trainable params: 103,073\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "disc = discriminator()\n",
    "disc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_out,fake_out):\n",
    "    \n",
    "    #这里希望让真实图像被判定为1,假的图像判定为0\n",
    "    real_loss = cross_entropy(tf.ones_like(real_out),real_out)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_out),fake_out)\n",
    "    \n",
    "    return real_loss + fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成器生成假的的图片并希望能够被判为真\n",
    "def generator_loss(fake_out):\n",
    "    return cross_entropy(tf.ones_like(fake_out),fake_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-5)   #创建优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(image,label):\n",
    "    size = label.shape[0]\n",
    "    noise = tf.random.normal([size,noise_dim])\n",
    "    with tf.GradientTape() as gen_tape,tf.GradientTape() as disc_tape:\n",
    "         \n",
    "        gen_image = gen((noise,label),training=True)\n",
    "        fake_out = disc((gen_image,label),training=True)\n",
    "        real_out = disc((image,label),training=True)\n",
    "         \n",
    "        gen_loss = generator_loss(fake_out)\n",
    "        disc_loss = discriminator_loss(real_out,fake_out)\n",
    "        \n",
    "    gradient_gen = gen_tape.gradient(gen_loss,gen.trainable_variables)\n",
    "    gradient_disc = disc_tape.gradient(disc_loss,disc.trainable_variables)\n",
    "    \n",
    "    generator_optimizer.apply_gradients(zip(gradient_gen,gen.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradient_disc,disc.trainable_variables))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#画出这一个批次的图片\n",
    "def generate_plot_image(model, noise, label,epoch_num):\n",
    "    print('Epoch:',epoch_num)\n",
    "    gen_image = model((noise,label),training=False)\n",
    "    gen_image = tf.squeeze(gen_image)  #(28,28,1) -->(None,28,28)\n",
    "    fig = plt.figure(figsize=(10,1))\n",
    "    for i in range(gen_image.shape[0]):\n",
    "        plt.subplot(1,10,i+1)   #1行10列\n",
    "        #因为在生成图片最后用激活函数tanh把图片映射到[-1,1]之间,现在要把取值范围改变成[0,1]的范围\n",
    "        plt.imshow((gen_image[i,:,:] + 1)/ 2)\n",
    "        plt.axis('off')    #不用显示坐标\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 1 2 6 6 0 3 5 6 0]]\n"
     ]
    }
   ],
   "source": [
    "num = 10\n",
    "noise_seed = tf.random.normal([num,noise_dim])\n",
    "label_seed = np.random.randint(0,10,size=(num,1))\n",
    "print(label_seed.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset,epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for image_bath ,label_batch in dataset:\n",
    "            train_step(image_bath,label_batch)\n",
    "        if epoch%10 ==0:\n",
    "            generate_plot_image(gen,noise_seed,label_seed,epoch)\n",
    "    generate_plot_image(gen,noise_seed,label_seed,epoch)   \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHES = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "ConcatOp : Ranks of all input tensors should match: shape[0] = [10,50] vs. shape[1] = [10,1,50] [Op:ConcatV2] name: concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-4154f43946dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mEPOCHES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-24-ae34be216919>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataset, epochs)\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_bath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mgenerate_plot_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnoise_seed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel_seed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mgenerate_plot_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnoise_seed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel_seed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-9d7dd441152c>\u001b[0m in \u001b[0;36mgenerate_plot_image\u001b[1;34m(model, noise, label, epoch_num)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgenerate_plot_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mgen_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mgen_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_image\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#(28,28,1) -->(None,28,28)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m           \u001b[1;31m# Compute outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m           \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m           \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\merge.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_merge_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_type_conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\merge.py\u001b[0m in \u001b[0;36m_merge_function\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_type_conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(tensors, axis)\u001b[0m\n\u001b[0;32m   2706\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_concat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2707\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2708\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1429\u001b[0m           dtype=dtypes.int32).get_shape().assert_has_rank(0)\n\u001b[0;32m   1430\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1431\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1247\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1249\u001b[1;33m       \u001b[0m_six\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1250\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Anaconda\\envs\\kr\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: ConcatOp : Ranks of all input tensors should match: shape[0] = [10,50] vs. shape[1] = [10,1,50] [Op:ConcatV2] name: concat"
     ]
    }
   ],
   "source": [
    "train(dataset,EPOCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
