{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(images,labels),(_,_) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape , labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2414f618dd8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images/127.5 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0, 1.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.min() , images.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.expand_dims(images,-1)  #用tensorflow方法还要对数据进行转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " dataset = tf.data.Dataset.from_tensor_slices((images,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((28, 28, 1), ()), types: (tf.float64, tf.uint8)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "noise_dim = 50\n",
    "con_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(60000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    noise_seed = layers.Input(shape=((noise_dim)))\n",
    "    label = layers.Input(shape=(()))\n",
    "    con_seed = layers.Input(shape=((con_dim)))\n",
    "    \n",
    "    x = layers.Embedding(10,50,input_length=1)(label)\n",
    "    x = layers.concatenate([noise_seed,x,con_seed])\n",
    "    x = layers.Dense(3*3*128,use_bias=False)(x)\n",
    "    x = layers.Reshape((3,3,128))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(64,(3,3), strides=(2,2),use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)   #(7,7,,64)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(32,(3,3), strides=(2,2),padding='same',use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)  #(14,14,32)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(1,(3,3), strides=(2,2),padding='same',use_bias=False)(x)\n",
    "    x = layers.Activation('tanh')(x)    #（28，28，1）\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[noise_seed,label,con_seed], outputs = x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50)           500         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 150)          0           input_1[0][0]                    \n",
      "                                                                 embedding[0][0]                  \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1152)         172800      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 3, 3, 128)    0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 3, 3, 128)    512         reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 3, 3, 128)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 7, 7, 64)     73728       re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 7, 7, 64)     256         conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 7, 7, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 14, 14, 32)   18432       re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 14, 14, 32)   128         conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 14, 14, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 28, 28, 1)    288         re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 28, 28, 1)    0           conv2d_transpose_2[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 266,644\n",
      "Trainable params: 266,196\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gen = generator()\n",
    "gen.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    image = layers.Input(shape=(28,28,1))\n",
    "    \n",
    "    x = layers.Conv2D(32,(3,3),strides=(2,2),padding='same',use_bias=False)(image)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    x = layers.Conv2D(64,(3,3),strides=(2,2),padding='same',use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    x = layers.Conv2D(128,(3,3),strides=(2,2),padding='same',use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    x1 = layers.Dense(1)(x)   #真假输出\n",
    "    x2 = layers.Dense(10)(x)  #分类输出\n",
    "    x3 = layers.Dense(con_dim)(x)  #condition输出即还原c\n",
    "    \n",
    "    model = tf.keras.Model(inputs=image, outputs = [x1,x2,x3])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 14, 14, 32)   288         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 14, 14, 32)   128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 14, 14, 32)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 14, 14, 32)   0           leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 7, 7, 64)     18432       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 7, 7, 64)     256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 7, 7, 64)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 64)     0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 4, 4, 128)    73728       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 4, 4, 128)    512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 4, 4, 128)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 4, 4, 128)    0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            2049        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20490       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 50)           102450      flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 218,333\n",
      "Trainable params: 217,885\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "disc = discriminator()\n",
    "disc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "cce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_out,real_cls_out,fake_out,label,con_out,con_in):\n",
    "    \n",
    "    #这里希望让真实图像被判定为1,假的图像判定为0\n",
    "    real_loss = cross_entropy(tf.ones_like(real_out),real_out)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_out),fake_out)\n",
    "    cat_loss = cce(label,real_cls_out)\n",
    "    con_loss = tf.reduce_mean(tf.square(con_out - con_in))  #平方误差\n",
    "    \n",
    "    return real_loss + fake_loss + cat_loss + con_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成器接收假的的图片并希望能够被判为真\n",
    "def generator_loss(fake_out,fake_cls_out,label,con_out,con_in):\n",
    "    fake_loss = cross_entropy(tf.ones_like(fake_out),fake_out)\n",
    "    cat_loss = cce(label,fake_cls_out)\n",
    "    con_loss = tf.reduce_mean(tf.square(con_out - con_in))  #平方误差\n",
    "    return fake_loss + cat_loss + con_loss\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-5)   #创建优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(image,label):\n",
    "    size = label.shape[0]\n",
    "    noise = tf.random.normal([size,noise_dim])\n",
    "    cond = tf.random.normal([size,con_dim])\n",
    "    with tf.GradientTape() as gen_tape,tf.GradientTape() as disc_tape:\n",
    "         \n",
    "        gen_image = gen((noise,cond,label),training=True)\n",
    "        fake_out,fake_cls_out,con_out = disc(gen_image,training=True)\n",
    "        real_out,real_cls_out, _ = disc(image,training=True)\n",
    "         \n",
    "        gen_loss = generator_loss(fake_out,fake_cls_out,label,con_out,cond)\n",
    "        disc_loss = discriminator_loss(real_out,real_cls_out,fake_out,label,con_out,cond)\n",
    "        \n",
    "    gradient_gen = gen_tape.gradient(gen_loss,gen.trainable_variables)\n",
    "    gradient_disc = disc_tape.gradient(disc_loss,disc.trainable_variables)\n",
    "    \n",
    "    generator_optimizer.apply_gradients(zip(gradient_gen,gen.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradient_disc,disc.trainable_variables))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#画出这一个批次的图片\n",
    "def generate_plot_image(model, noise, label,epoch_num,cond):\n",
    "    print('Epoch:',epoch_num)\n",
    "    # cond = tf.random.normal([size,con_dim])\n",
    "    gen_image = model((noise,cond,label),training=False)\n",
    "    gen_image = tf.squeeze(gen_image)  #(28,28,1) -->(None,28,28)\n",
    "    fig = plt.figure(figsize=(10,1))\n",
    "    for i in range(gen_image.shape[0]):\n",
    "        plt.subplot(1,10,i+1)   #1行10列\n",
    "        #因为在生成图片最后用激活函数tanh把图片映射到[-1,1]之间,现在要把取值范围改变成[0,1]的范围\n",
    "        plt.imshow((gen_image[i,:,:] + 1)/ 2)\n",
    "        plt.axis('off')    #不用显示坐标\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 6 1 5 9 4 0 7 5 3]\n"
     ]
    }
   ],
   "source": [
    "num = 10\n",
    "noise_seed = tf.random.normal([num,noise_dim])\n",
    "label_seed = np.random.randint(0,10,size=(num))\n",
    "print(label_seed.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset,epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for image_bath ,label_batch in dataset:\n",
    "            train_step(image_bath,label_batch)\n",
    "        if epoch%10 ==0:\n",
    "            cond = tf.random.normal([size,con_dim])\n",
    "            generate_plot_image(gen,noise_seed,label_seed,epoch,cond)\n",
    "    cond = tf.random.normal([size,con_dim])    \n",
    "    generate_plot_image(gen,noise_seed,label_seed,epoch,cond)   \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHES = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in converted code:\n\n    <ipython-input-21-5fcef9b02640>:8 train_step  *\n        gen_image = gen((noise,cond,label),training=True)\n    A:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py:847 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    A:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py:708 call\n        convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n    A:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py:860 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    A:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py:847 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    A:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\merge.py:182 call\n        return self._merge_function(inputs)\n    A:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\merge.py:394 _merge_function\n        return K.concatenate(inputs, axis=self.axis)\n    A:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py:2708 concatenate\n        return array_ops.concat([to_dense(x) for x in tensors], axis)\n    A:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py:180 wrapper\n        return target(*args, **kwargs)\n    A:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py:1431 concat\n        return gen_array_ops.concat_v2(values=values, axis=axis, name=name)\n    A:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py:1257 concat_v2\n        \"ConcatV2\", values=values, axis=axis, name=name)\n    A:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py:499 _apply_op_helper\n        raise TypeError(\"%s that don't all match.\" % prefix)\n\n    TypeError: Tensors in list passed to 'values' of 'ConcatV2' Op have types [float32, float32, uint8] that don't all match.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-4154f43946dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mEPOCHES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-24-464cd6693ea2>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataset, epochs)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mimage_bath\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mlabel_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m             \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_bath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    501\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m       \u001b[0minitializer_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    406\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    407\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 408\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2150\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2152\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2041\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2043\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    913\u001b[0m                                           converted_func)\n\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    903\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 905\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    906\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in converted code:\n\n    <ipython-input-21-5fcef9b02640>:8 train_step  *\n        gen_image = gen((noise,cond,label),training=True)\n    A:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py:847 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    A:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py:708 call\n        convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n    A:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py:860 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    A:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py:847 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    A:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\merge.py:182 call\n        return self._merge_function(inputs)\n    A:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\merge.py:394 _merge_function\n        return K.concatenate(inputs, axis=self.axis)\n    A:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py:2708 concatenate\n        return array_ops.concat([to_dense(x) for x in tensors], axis)\n    A:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py:180 wrapper\n        return target(*args, **kwargs)\n    A:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py:1431 concat\n        return gen_array_ops.concat_v2(values=values, axis=axis, name=name)\n    A:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py:1257 concat_v2\n        \"ConcatV2\", values=values, axis=axis, name=name)\n    A:\\Anaconda\\envs\\kr\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py:499 _apply_op_helper\n        raise TypeError(\"%s that don't all match.\" % prefix)\n\n    TypeError: Tensors in list passed to 'values' of 'ConcatV2' Op have types [float32, float32, uint8] that don't all match.\n"
     ]
    }
   ],
   "source": [
    "train(dataset,EPOCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
